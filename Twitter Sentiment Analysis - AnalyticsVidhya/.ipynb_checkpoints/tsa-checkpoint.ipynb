{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for nlp\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAHUL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAd the dataset\n",
    "data = pd.read_csv('dataset//train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerprocessing function\n",
    "def pre_process(tweet):\n",
    "    '''\n",
    "    tweet: tweet is a long string (i.e individual tweet)\n",
    "    final_list = return list of words\n",
    "    '''\n",
    "    \n",
    "    # lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
    "    \n",
    "    # tokenization\n",
    "    tweet_l = word_tokenize(tweet)\n",
    "    \n",
    "    # remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    tweet_l = [word for word in tweet_l if word not in stop_words]\n",
    "    \n",
    "    # stemming\n",
    "    porter = PorterStemmer()\n",
    "    final_list = [porter.stem(word) for word in tweet_l]\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'rahul']\n"
     ]
    }
   ],
   "source": [
    "# Testing the above function\n",
    "t = \"This is me! Hey, It's rahul.\"\n",
    "res = pre_process(t)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all corpora\n",
    "X = []\n",
    "for tweet in data['tweet']:\n",
    "    tweet = pre_process(tweet)\n",
    "    X.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user',\n",
       " 'father',\n",
       " 'dysfunct',\n",
       " 'selfish',\n",
       " 'drag',\n",
       " 'kid',\n",
       " 'dysfunct',\n",
       " 'run',\n",
       " 'user',\n",
       " 'user',\n",
       " 'thank',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " 'cant',\n",
       " 'use',\n",
       " 'caus',\n",
       " 'dont',\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'van',\n",
       " 'pdx',\n",
       " 'disapoint',\n",
       " 'getthank',\n",
       " 'bihday',\n",
       " 'majesti',\n",
       " 'model',\n",
       " 'love',\n",
       " 'u',\n",
       " 'take',\n",
       " 'u',\n",
       " 'time',\n",
       " 'urð\\x9f\\x93±',\n",
       " 'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91',\n",
       " 'ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
       " 'factsguid',\n",
       " 'societi',\n",
       " 'motiv',\n",
       " '22',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'fare',\n",
       " 'big',\n",
       " 'talk',\n",
       " 'leav',\n",
       " 'chao',\n",
       " 'pay',\n",
       " 'disput',\n",
       " 'get',\n",
       " 'allshowandnogo',\n",
       " 'user',\n",
       " 'camp',\n",
       " 'tomorrow',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'dannyâ\\x80¦',\n",
       " 'next',\n",
       " 'school',\n",
       " 'year',\n",
       " 'year',\n",
       " 'examsð\\x9f\\x98¯',\n",
       " 'cant',\n",
       " 'think',\n",
       " 'ð\\x9f\\x98\\xad',\n",
       " 'school',\n",
       " 'exam',\n",
       " 'hate',\n",
       " 'imagin',\n",
       " 'actorslif',\n",
       " 'revolutionschool',\n",
       " 'girl',\n",
       " 'love',\n",
       " 'land',\n",
       " 'allin',\n",
       " 'cav',\n",
       " 'champion',\n",
       " 'cleveland',\n",
       " 'clevelandcavali',\n",
       " 'â\\x80¦',\n",
       " 'user',\n",
       " 'user',\n",
       " 'welcom',\n",
       " 'im',\n",
       " 'gr8',\n",
       " 'â\\x86\\x9d',\n",
       " 'ireland',\n",
       " 'consum',\n",
       " 'price',\n",
       " 'index',\n",
       " 'mom',\n",
       " 'climb',\n",
       " 'previou',\n",
       " '02',\n",
       " '05',\n",
       " 'may',\n",
       " 'blog',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'forex',\n",
       " 'selfish',\n",
       " 'orlando',\n",
       " 'standwithorlando',\n",
       " 'pulseshoot',\n",
       " 'orlandoshoot',\n",
       " 'biggerproblem',\n",
       " 'selfish',\n",
       " 'heabreak',\n",
       " 'valu',\n",
       " 'love',\n",
       " 'get',\n",
       " 'see',\n",
       " 'daddi',\n",
       " 'today',\n",
       " '80day',\n",
       " 'gettingf',\n",
       " 'user',\n",
       " 'cnn',\n",
       " 'call',\n",
       " 'michigan',\n",
       " 'middl',\n",
       " 'school',\n",
       " 'build',\n",
       " 'wall',\n",
       " 'chant',\n",
       " 'tcot',\n",
       " 'comment',\n",
       " 'australia',\n",
       " 'opkillingbay',\n",
       " 'seashepherd',\n",
       " 'helpcovedolphin',\n",
       " 'thecov',\n",
       " 'helpcovedolphin',\n",
       " 'ouchjunior',\n",
       " 'angryð\\x9f\\x98\\x90got7',\n",
       " 'junior',\n",
       " 'yugyoem',\n",
       " 'omg',\n",
       " 'thank',\n",
       " 'paner',\n",
       " 'thank',\n",
       " 'posit',\n",
       " 'retweet',\n",
       " 'agre',\n",
       " 'friday',\n",
       " 'ð\\x9f\\x98\\x80',\n",
       " 'smile',\n",
       " 'around',\n",
       " 'via',\n",
       " 'ig',\n",
       " 'user',\n",
       " 'user',\n",
       " 'cooki',\n",
       " 'make',\n",
       " 'peopl',\n",
       " 'know',\n",
       " 'essenti',\n",
       " 'oil',\n",
       " 'made',\n",
       " 'chemic',\n",
       " 'euro2016',\n",
       " 'peopl',\n",
       " 'blame',\n",
       " 'ha',\n",
       " 'conced',\n",
       " 'goal',\n",
       " 'fat',\n",
       " 'rooney',\n",
       " 'gave',\n",
       " 'away',\n",
       " 'free',\n",
       " 'kick',\n",
       " 'know',\n",
       " 'bale',\n",
       " 'hit',\n",
       " 'sad',\n",
       " 'littl',\n",
       " 'dude',\n",
       " 'badday',\n",
       " 'coneofsham',\n",
       " 'cat',\n",
       " 'piss',\n",
       " 'funni',\n",
       " 'laugh',\n",
       " 'product',\n",
       " 'day',\n",
       " 'happi',\n",
       " 'man',\n",
       " 'wine',\n",
       " 'tool',\n",
       " 'who',\n",
       " 'weekend',\n",
       " 'time',\n",
       " 'open',\n",
       " 'amp',\n",
       " 'drink',\n",
       " 'user',\n",
       " 'user',\n",
       " 'lumpi',\n",
       " 'say',\n",
       " 'prove',\n",
       " 'lumpi',\n",
       " 'user',\n",
       " 'tgif',\n",
       " 'ff',\n",
       " 'gamedev',\n",
       " 'indiedev',\n",
       " 'indiegamedev',\n",
       " 'squad',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'beauti',\n",
       " 'sign',\n",
       " 'vendor',\n",
       " '80',\n",
       " '4500',\n",
       " 'upsideofflorida',\n",
       " 'shopalyssa',\n",
       " 'love',\n",
       " 'user',\n",
       " 'smile',\n",
       " 'media',\n",
       " 'ð\\x9f\\x98\\x9cð\\x9f\\x98\\x88',\n",
       " 'pressconfer',\n",
       " 'antalya',\n",
       " 'turkey',\n",
       " 'sunday',\n",
       " 'throwback',\n",
       " 'love',\n",
       " 'ð\\x9f\\x98\\x8að\\x9f\\x98\\x98â\\x9d¤ï¸\\x8f',\n",
       " 'great',\n",
       " 'panel',\n",
       " 'mediat',\n",
       " 'public',\n",
       " 'servic',\n",
       " 'ica16',\n",
       " 'happi',\n",
       " 'father',\n",
       " 'day',\n",
       " 'user',\n",
       " 'ð\\x9f\\x92\\x93ð\\x9f\\x92\\x93ð\\x9f\\x92\\x93ð\\x9f\\x92\\x93',\n",
       " '50',\n",
       " 'peopl',\n",
       " 'went',\n",
       " 'nightclub',\n",
       " 'good',\n",
       " 'night',\n",
       " '1',\n",
       " 'man',\n",
       " 'action',\n",
       " 'mean',\n",
       " 'peopl',\n",
       " 'lost',\n",
       " 'famili',\n",
       " 'forev',\n",
       " 'riporlando',\n",
       " 'never',\n",
       " 'chanc',\n",
       " 'vote',\n",
       " 'presidenti',\n",
       " 'candid',\n",
       " 'excit',\n",
       " 'cycl',\n",
       " 'look',\n",
       " 'differ',\n",
       " 'alohafriday',\n",
       " 'time',\n",
       " 'exist',\n",
       " 'positivevib',\n",
       " 'hawaiian',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'rip',\n",
       " 'fellow',\n",
       " 'nohern',\n",
       " 'ireland',\n",
       " 'fan',\n",
       " 'sadley',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'tonight',\n",
       " 'gawa',\n",
       " 'forev',\n",
       " 'sing',\n",
       " 'cheer',\n",
       " 'fire',\n",
       " 'hard',\n",
       " 'monday',\n",
       " 'due',\n",
       " 'cloudi',\n",
       " 'weather',\n",
       " 'disabl',\n",
       " 'oxygen',\n",
       " 'product',\n",
       " 'today',\n",
       " 'goodnight',\n",
       " 'badmonday',\n",
       " 'unbeliev',\n",
       " '21st',\n",
       " 'centuri',\n",
       " 'wed',\n",
       " 'need',\n",
       " 'someth',\n",
       " 'like',\n",
       " 'neverump',\n",
       " 'xenophobia',\n",
       " 'taylorswift1989',\n",
       " 'bull',\n",
       " 'domin',\n",
       " 'bull',\n",
       " 'direct',\n",
       " 'whatev',\n",
       " 'want',\n",
       " 'w',\n",
       " 'morn',\n",
       " 'travelingram',\n",
       " 'dalat',\n",
       " 'ripinkylif',\n",
       " 'user',\n",
       " 'one',\n",
       " 'word',\n",
       " 'tell',\n",
       " 'photoshop',\n",
       " 'enoughisenough',\n",
       " 'dontphotoshopeveryth',\n",
       " 'wheresallthenaturalphoto',\n",
       " 'oh',\n",
       " 'cedarpoint',\n",
       " 'wait',\n",
       " '2',\n",
       " 'hour',\n",
       " 'valravn',\n",
       " 'line',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'close',\n",
       " 'thank',\n",
       " 'sunshin',\n",
       " 'thank',\n",
       " 'posit',\n",
       " 'final',\n",
       " 'finish',\n",
       " 'book',\n",
       " 'youv',\n",
       " 'work',\n",
       " 'awhil',\n",
       " 'bookworm',\n",
       " 'ontothenextnovel',\n",
       " 'yup',\n",
       " 'knick',\n",
       " 'fan',\n",
       " 'hard',\n",
       " 'easier',\n",
       " 'nba',\n",
       " 'fan',\n",
       " 'playoff',\n",
       " 'roll',\n",
       " 'around',\n",
       " 'ð\\x9f\\x98\\x8e',\n",
       " 'life',\n",
       " 'social',\n",
       " 'network',\n",
       " 'embrac',\n",
       " 'day',\n",
       " 'mom',\n",
       " 'share',\n",
       " 'bihday',\n",
       " 'user',\n",
       " 'bihday',\n",
       " 'snake',\n",
       " 'see',\n",
       " 'weekend',\n",
       " 'ð\\x9f\\x99\\x8cð\\x9f\\x8f¼',\n",
       " 'love',\n",
       " 'echeveria',\n",
       " 'bloomsflow',\n",
       " 'grow',\n",
       " 'garden',\n",
       " 'iphonesia',\n",
       " 'bliss',\n",
       " 'bloom',\n",
       " 'basilicabotanica',\n",
       " 'amaz',\n",
       " 'iam',\n",
       " 'posit',\n",
       " 'affirm',\n",
       " 'model',\n",
       " 'love',\n",
       " 'u',\n",
       " 'take',\n",
       " 'u',\n",
       " 'time',\n",
       " 'urð\\x9f\\x93±',\n",
       " 'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91',\n",
       " 'ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
       " 'whenev',\n",
       " 'im',\n",
       " 'someth',\n",
       " 'goe',\n",
       " 'wrong',\n",
       " 'feel',\n",
       " 'blue',\n",
       " 'illustr',\n",
       " 'best',\n",
       " 'pa',\n",
       " 'life',\n",
       " 'know',\n",
       " 'ð\\x9f\\x98\\x8aâ\\x98\\x80ï¸\\x8fð\\x9f\\x8c¼ð\\x9f\\x8c',\n",
       " '»',\n",
       " 'â\\x80¦',\n",
       " 'abc2020',\n",
       " 'get',\n",
       " 'readi',\n",
       " '2',\n",
       " 'remov',\n",
       " 'victum',\n",
       " 'frm',\n",
       " 'pulseclub',\n",
       " 'prayfororlando',\n",
       " 'bihday',\n",
       " 'got',\n",
       " 'nose',\n",
       " 'job',\n",
       " 'user',\n",
       " 'ð\\x9f\\x8e\\x88ð\\x9f\\x90¶ð\\x9f\\x8e\\x89ð\\x9f\\x8e\\x82ð\\x9f\\x8e\\x81',\n",
       " 'bihday',\n",
       " 'petunia',\n",
       " 'love',\n",
       " 'ð\\x9f\\x99\\x83',\n",
       " 'concelebr',\n",
       " 'albanpilgrimag',\n",
       " 'first',\n",
       " 'time',\n",
       " 'user',\n",
       " 'user',\n",
       " 'let',\n",
       " 'scumbaggeri',\n",
       " 'begin',\n",
       " 'thank',\n",
       " 'ð\\x9f\\x98\\x8dð\\x9f\\x98\\x86',\n",
       " 'super',\n",
       " 'love',\n",
       " 'â\\x9d¤ï¸\\x8f',\n",
       " 'zpamdelacruz',\n",
       " 'wed',\n",
       " 'dolor',\n",
       " 'capa',\n",
       " 'tarlac',\n",
       " 'scourg',\n",
       " 'play',\n",
       " 'baroqu',\n",
       " 'piec',\n",
       " 'piano',\n",
       " 'beyond',\n",
       " 'belief',\n",
       " 'user',\n",
       " 'let',\n",
       " 'fight',\n",
       " 'love',\n",
       " 'peac',\n",
       " 'happi',\n",
       " 'fatherâ\\x80\\x99',\n",
       " 'day',\n",
       " 'mr',\n",
       " 'rayo',\n",
       " 'video',\n",
       " 'father',\n",
       " 'day',\n",
       " 'rayo',\n",
       " 'world',\n",
       " 'hotvideo',\n",
       " 'video',\n",
       " 'user',\n",
       " 'ascot',\n",
       " 'time',\n",
       " 'babe',\n",
       " 'â\\x9d¤ï¸\\x8fâ\\x9d¤ï¸\\x8f',\n",
       " 'ascot',\n",
       " 'fashion',\n",
       " 'monochrom',\n",
       " 'style',\n",
       " 'instahappyday',\n",
       " 'weekendi',\n",
       " 'hereð\\x9f\\x99\\x8cð\\x9f\\x98\\x89ð\\x9f\\x98\\x98ð\\x9f\\x92\\x99ð\\x9f\\x98\\x8a',\n",
       " 'selfi',\n",
       " 'yolo',\n",
       " 'xoxo',\n",
       " 'like4lik',\n",
       " 'happi',\n",
       " 'work',\n",
       " 'confer',\n",
       " 'right',\n",
       " 'mindset',\n",
       " 'lead',\n",
       " 'cultureofdevelop',\n",
       " 'organ',\n",
       " 'work',\n",
       " 'mindset',\n",
       " 'christina',\n",
       " 'grimmi',\n",
       " 'last',\n",
       " 'perform',\n",
       " 'shot',\n",
       " 'via',\n",
       " 'user',\n",
       " 'christinarip',\n",
       " 'voic',\n",
       " 'christinagrimmi',\n",
       " 'readi',\n",
       " 'danc',\n",
       " 'roar',\n",
       " 'preschool',\n",
       " 'student',\n",
       " 'proudâ\\x80¦',\n",
       " 'youv',\n",
       " 'realli',\n",
       " 'hu',\n",
       " 'feel',\n",
       " 'user',\n",
       " 'wife',\n",
       " 'ador',\n",
       " 'miss',\n",
       " 'poland',\n",
       " 'show',\n",
       " 'surgeri',\n",
       " 'name',\n",
       " 'bridget',\n",
       " 'amp',\n",
       " 'she',\n",
       " 'everyth',\n",
       " 'user',\n",
       " 'jealou',\n",
       " 'right',\n",
       " 'chatiado',\n",
       " 'celebr',\n",
       " 'everi',\n",
       " 'man',\n",
       " 'play',\n",
       " 'fatherli',\n",
       " 'role',\n",
       " 'father',\n",
       " 'day',\n",
       " 'im',\n",
       " 'sure',\n",
       " 'happi',\n",
       " 'ð\\x9f\\x91\\x8fð\\x9f\\x8f½ð\\x9f\\x91\\x8fð\\x9f\\x8f½ð\\x9f\\x91\\x8fð\\x9f\\x8f½',\n",
       " 'hour',\n",
       " 'ð\\x9f\\x98©the',\n",
       " 'white',\n",
       " 'establish',\n",
       " 'cant',\n",
       " 'blk',\n",
       " 'folx',\n",
       " 'run',\n",
       " 'around',\n",
       " 'love',\n",
       " 'promot',\n",
       " 'great',\n",
       " 'good',\n",
       " 'morn',\n",
       " 'journey',\n",
       " 'begin',\n",
       " 'ð\\x9f\\x98\\x84ð\\x9f\\x91\\x8dð\\x9f\\x8f',\n",
       " '»',\n",
       " 'ð\\x9f\\x9b³',\n",
       " 'travel',\n",
       " 'yeah',\n",
       " 'thejourneybegin',\n",
       " 'helloâ\\x80¦',\n",
       " 'user',\n",
       " 'luv',\n",
       " 'hottweet',\n",
       " 'like',\n",
       " 'â\\x96¶',\n",
       " 'â\\x99¥venusexchangeâ\\x99¥',\n",
       " 'new',\n",
       " 'brochur',\n",
       " 'arriv',\n",
       " 'excit',\n",
       " 'awork',\n",
       " 'solut',\n",
       " 'much',\n",
       " 'stuff',\n",
       " 'happen',\n",
       " 'florida',\n",
       " 'first',\n",
       " 'orlando',\n",
       " 'shoot',\n",
       " 'disneygatorattack',\n",
       " 'two',\n",
       " 'year',\n",
       " 'old',\n",
       " 'kidð\\x9f\\x98¥ð\\x9f\\x90\\x8a',\n",
       " 'user',\n",
       " 'ferrari',\n",
       " 'itð\\x9f\\x92ªð\\x9f\\x8f¼',\n",
       " 'sake',\n",
       " 'championship',\n",
       " 'gp',\n",
       " 'clearli',\n",
       " 'turn',\n",
       " 'point',\n",
       " 'rb',\n",
       " 'ferrarimercsð\\x9f\\x98\\x8d',\n",
       " 'ace',\n",
       " 'first',\n",
       " 'test',\n",
       " 'proud',\n",
       " 'seek',\n",
       " 'probe',\n",
       " 'udtapunjab',\n",
       " 'leak',\n",
       " 'point',\n",
       " 'finger',\n",
       " 'amarind',\n",
       " 'aap',\n",
       " 'user',\n",
       " 'wrap',\n",
       " 'senseaboutmath',\n",
       " 'user',\n",
       " '6th',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'hey',\n",
       " 'white',\n",
       " 'peopl',\n",
       " 'call',\n",
       " 'peopl',\n",
       " 'white',\n",
       " 'user',\n",
       " 'race',\n",
       " 'ident',\n",
       " 'medâ\\x80¦',\n",
       " 'user',\n",
       " 'user',\n",
       " 'might',\n",
       " 'shown',\n",
       " 'today',\n",
       " 'regurgit',\n",
       " 'talk',\n",
       " 'point',\n",
       " 'name',\n",
       " 'call',\n",
       " 'sometim',\n",
       " 'rais',\n",
       " 'brow',\n",
       " 'rais',\n",
       " 'bar',\n",
       " 'golfstrengthandcondit',\n",
       " 'strong',\n",
       " 'felixfoisgolf',\n",
       " 'ð\\x9f\\x98\\x80ð\\x9f\\x98\\x80ð\\x9f\\x98\\x80',\n",
       " 'greathonour',\n",
       " 'careerconvo',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'design',\n",
       " 'innov',\n",
       " 'learn',\n",
       " 'space',\n",
       " 'user',\n",
       " 'includ',\n",
       " 'wateringhol',\n",
       " 'cave',\n",
       " 'mountaintop',\n",
       " 'campfir',\n",
       " 'user',\n",
       " 'hâ\\x80¦',\n",
       " 'altright',\n",
       " 'use',\n",
       " 'amp',\n",
       " 'insecur',\n",
       " 'lure',\n",
       " 'men',\n",
       " 'whitesupremaci',\n",
       " 'carri',\n",
       " 'gun',\n",
       " 'wouldnt',\n",
       " 'help',\n",
       " 'cant',\n",
       " 'take',\n",
       " 'gun',\n",
       " 'control',\n",
       " 'wont',\n",
       " 'stop',\n",
       " 'black',\n",
       " 'market',\n",
       " 'terror',\n",
       " 'get',\n",
       " 'wors',\n",
       " 'use',\n",
       " 'power',\n",
       " 'mind',\n",
       " 'heal',\n",
       " 'bodi',\n",
       " 'altwaystoh',\n",
       " 'healthi',\n",
       " 'peac',\n",
       " 'woohoo',\n",
       " '5',\n",
       " 'week',\n",
       " 'go',\n",
       " 'far',\n",
       " 'away',\n",
       " 'place',\n",
       " 'famili',\n",
       " 'member',\n",
       " 'hu',\n",
       " 'readi',\n",
       " 'rehears',\n",
       " 'tonight',\n",
       " 'new',\n",
       " 'music',\n",
       " 'new',\n",
       " 'video',\n",
       " 'look',\n",
       " 'announc',\n",
       " 'midweek',\n",
       " 'newmus',\n",
       " 'watchthisspac',\n",
       " 'guitar',\n",
       " 'monday',\n",
       " 'night',\n",
       " '8pm',\n",
       " 'channel',\n",
       " 'final',\n",
       " 'get',\n",
       " 'see',\n",
       " 'fuss',\n",
       " 'watch',\n",
       " 'new',\n",
       " 'episod',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'offlin',\n",
       " 'nice',\n",
       " 'long',\n",
       " 'night',\n",
       " 'ð\\x9f\\x98\\x9a',\n",
       " 'snapchat',\n",
       " 'user',\n",
       " 'redhead',\n",
       " 'vermillionr',\n",
       " '15',\n",
       " 'thing',\n",
       " 'incred',\n",
       " 'peopl',\n",
       " 'ye',\n",
       " 'receiv',\n",
       " 'accept',\n",
       " 'letter',\n",
       " 'master',\n",
       " 'back',\n",
       " 'user',\n",
       " 'octob',\n",
       " 'goodtim',\n",
       " 'histori',\n",
       " 'daughter',\n",
       " 'ride',\n",
       " 'bike',\n",
       " 'around',\n",
       " 'driveway',\n",
       " 'son',\n",
       " 'play',\n",
       " 'guitar',\n",
       " 'us',\n",
       " 'enjoy',\n",
       " 'ð\\x9f\\x8dº',\n",
       " 'campfir',\n",
       " 'summeim',\n",
       " 'memori',\n",
       " 'omg',\n",
       " 'love',\n",
       " 'station',\n",
       " 'way',\n",
       " 'jam',\n",
       " 'work',\n",
       " 'get',\n",
       " 'work',\n",
       " 'done',\n",
       " 'cours',\n",
       " 'memori',\n",
       " 'user',\n",
       " 'user',\n",
       " 'ill',\n",
       " 'alway',\n",
       " 'hope',\n",
       " 'one',\n",
       " 'day',\n",
       " 'ill',\n",
       " 'get',\n",
       " 'hug',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'happen',\n",
       " 'anytim',\n",
       " 'soon',\n",
       " 'model',\n",
       " 'love',\n",
       " 'u',\n",
       " 'take',\n",
       " 'u',\n",
       " 'time',\n",
       " 'urð\\x9f\\x93±',\n",
       " 'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91',\n",
       " 'ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
       " 'coupl',\n",
       " 'sex',\n",
       " 'fat',\n",
       " 'nake',\n",
       " 'japanes',\n",
       " 'girl',\n",
       " 'hump',\n",
       " 'hump',\n",
       " 'day',\n",
       " 'humpersð\\x9f\\x98©',\n",
       " 'edwardsvil',\n",
       " 'pennsylvania',\n",
       " 'personalis',\n",
       " 'gbp',\n",
       " '799',\n",
       " 'get',\n",
       " 'shop',\n",
       " 'cool',\n",
       " 'home',\n",
       " 'fun',\n",
       " 'truli',\n",
       " 'sick',\n",
       " 'ppl',\n",
       " 'trump',\n",
       " 'call',\n",
       " 'obama',\n",
       " 'resign',\n",
       " 'orlando',\n",
       " 'shoot',\n",
       " 'boy',\n",
       " 'point',\n",
       " '8',\n",
       " 'year',\n",
       " 'talk',\n",
       " 'chang',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'long',\n",
       " 'nashvilletour2016',\n",
       " 'nashvilleforev',\n",
       " 'ð\\x9f\\x92\\x96ð\\x9f\\x92\\x96ð\\x9f\\x92\\x96',\n",
       " 'â\\x86\\x9d',\n",
       " 'eurusd',\n",
       " 'clear',\n",
       " '11400',\n",
       " 'barrier',\n",
       " 'jump',\n",
       " 'fresh',\n",
       " '4week',\n",
       " 'high',\n",
       " 'blog',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'forex',\n",
       " 'go',\n",
       " 'la',\n",
       " 'tomorrow',\n",
       " 'thank',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'thank',\n",
       " 'posit',\n",
       " 'still',\n",
       " 'wrap',\n",
       " 'head',\n",
       " 'around',\n",
       " 'fact',\n",
       " 'christinagrimmi',\n",
       " 'gone',\n",
       " 'fact',\n",
       " 'man',\n",
       " 'destroy',\n",
       " 'prayfororlando',\n",
       " 'receiv',\n",
       " 'di',\n",
       " 'user',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'sta',\n",
       " 'bake',\n",
       " 'eyelid',\n",
       " 'ð\\x9f\\x98\\x9að\\x9f\\x98\\x9að\\x9f\\x98\\x8eð\\x9f\\x98\\x8eð\\x9f\\x98\\x8eð\\x9f\\x98\\x8e',\n",
       " 'ð\\x9f\\x98\\x89ð\\x9f\\x98\\x89ð\\x9f\\x98\\x89â\\x80¦',\n",
       " 'play',\n",
       " 'vigilfororlando',\n",
       " 'harp',\n",
       " 'clonakilti',\n",
       " 'rip',\n",
       " 'via',\n",
       " 'user',\n",
       " 'user',\n",
       " 'ye',\n",
       " 'ye',\n",
       " 'ye',\n",
       " 'ihavenofriend',\n",
       " 'someonecomewithm',\n",
       " 'sundayð\\x9f\\x92\\x95',\n",
       " 'weekend',\n",
       " 'relax',\n",
       " 'icon',\n",
       " 'woman',\n",
       " 'sundaymorn',\n",
       " 'sunday',\n",
       " 'marilynmonro',\n",
       " 'user',\n",
       " 'im',\n",
       " 'interest',\n",
       " 'linguist',\n",
       " 'doesnt',\n",
       " 'address',\n",
       " 'race',\n",
       " 'amp',\n",
       " 'racism',\n",
       " 'power',\n",
       " 'raciolinguist',\n",
       " 'bringsâ\\x80¦',\n",
       " 'one',\n",
       " 'belov',\n",
       " 'long',\n",
       " 'lost',\n",
       " 'cd',\n",
       " 'recov',\n",
       " 'thank',\n",
       " 'appl',\n",
       " 'music',\n",
       " 'marvel',\n",
       " 'song',\n",
       " 'musica',\n",
       " 'weed',\n",
       " 'ripchristina',\n",
       " 'adel',\n",
       " 'danc',\n",
       " 'vine',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'mock',\n",
       " 'obama',\n",
       " 'black',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'user',\n",
       " 'brexit',\n",
       " 'â\\x86\\x9d',\n",
       " 'spell',\n",
       " 'brexit',\n",
       " 'referendum',\n",
       " 'commerzbank',\n",
       " 'blog',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'forex',\n",
       " '100',\n",
       " 'amaz',\n",
       " 'health',\n",
       " 'benefit',\n",
       " 'cucumb',\n",
       " 'healthi',\n",
       " 'altwaystoh',\n",
       " 'model',\n",
       " 'love',\n",
       " 'u',\n",
       " 'take',\n",
       " 'u',\n",
       " 'time',\n",
       " 'urð\\x9f\\x93±',\n",
       " 'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91',\n",
       " 'ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
       " 'work',\n",
       " 'ð\\x9f\\x92ªð\\x9f\\x8f',\n",
       " '»',\n",
       " 'ð\\x9f\\x9a¶ð\\x9f\\x8f¼',\n",
       " 'ofw',\n",
       " 'pinoy',\n",
       " 'followm',\n",
       " 'iger',\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_l = []\n",
    "for lst in x:\n",
    "    vocab_l += lst\n",
    "vocab_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281668"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41367"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(vocab_l)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 41367)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_X = np.zeros([len(X), len(vocab)], dtype = 'int8')\n",
    "df = pd.DataFrame(empty_X, columns=list(vocab))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqs(lst):\n",
    "    '''\n",
    "    lst: list type (each processed tweets)\n",
    "    \n",
    "    return\n",
    "    dict: {word:freq}\n",
    "    '''\n",
    "    dict = {}\n",
    "    for word in lst:\n",
    "        if word in dict.keys():\n",
    "            dict[word] += 1\n",
    "        else:\n",
    "            dict[word] = 1\n",
    "            \n",
    "    return dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hey': 1, 'rahul': 1}\n"
     ]
    }
   ],
   "source": [
    "# test above function implementation\n",
    "print(get_freqs(pre_process(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gunner</th>\n",
       "      <th>yourslef</th>\n",
       "      <th>jokeâ¦</th>\n",
       "      <th>latenighttv</th>\n",
       "      <th>hotti</th>\n",
       "      <th>follow4followâ¦</th>\n",
       "      <th>instapicinstagoodinstafashionâ¦</th>\n",
       "      <th>summerbodi</th>\n",
       "      <th>872</th>\n",
       "      <th>taeilthailand</th>\n",
       "      <th>...</th>\n",
       "      <th>jel</th>\n",
       "      <th>askgat</th>\n",
       "      <th>nutti</th>\n",
       "      <th>weakdonaldtrump</th>\n",
       "      <th>willamett</th>\n",
       "      <th>mybihdaybyclassm</th>\n",
       "      <th>hbdtahirgond</th>\n",
       "      <th>ð¯ð</th>\n",
       "      <th>steveâ</th>\n",
       "      <th>nonton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gunner  yourslef  jokeâ¦  latenighttv  hotti  follow4followâ¦  \\\n",
       "0       0         0        0            0      0                 0   \n",
       "1       0         0        0            0      0                 0   \n",
       "2       0         0        0            0      0                 0   \n",
       "3       0         0        0            0      0                 0   \n",
       "4       0         0        0            0      0                 0   \n",
       "\n",
       "   instapicinstagoodinstafashionâ¦  summerbodi  872  taeilthailand  ...  jel  \\\n",
       "0                                 0           0    0              0  ...    0   \n",
       "1                                 0           0    0              0  ...    0   \n",
       "2                                 0           0    0              0  ...    0   \n",
       "3                                 0           0    0              0  ...    0   \n",
       "4                                 0           0    0              0  ...    0   \n",
       "\n",
       "   askgat  nutti  weakdonaldtrump  willamett  mybihdaybyclassm  hbdtahirgond  \\\n",
       "0       0      0                0          0                 0             0   \n",
       "1       0      0                0          0                 0             0   \n",
       "2       0      0                0          0                 0             0   \n",
       "3       0      0                0          0                 0             0   \n",
       "4       0      0                0          0                 0             0   \n",
       "\n",
       "   ð¯ð  steveâ  nonton  \n",
       "0         0         0       0  \n",
       "1         0         0       0  \n",
       "2         0         0       0  \n",
       "3         0         0       0  \n",
       "4         0         0       0  \n",
       "\n",
       "[5 rows x 41367 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[0, 'hotti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 tweet\n",
      "Processing 1 tweet\n",
      "Processing 2 tweet\n",
      "Processing 3 tweet\n",
      "Processing 4 tweet\n",
      "Processing 5 tweet\n",
      "Processing 6 tweet\n",
      "Processing 7 tweet\n",
      "Processing 8 tweet\n",
      "Processing 9 tweet\n",
      "Processing 10 tweet\n",
      "Processing 11 tweet\n",
      "Processing 12 tweet\n",
      "Processing 13 tweet\n",
      "Processing 14 tweet\n",
      "Processing 15 tweet\n",
      "Processing 16 tweet\n",
      "Processing 17 tweet\n",
      "Processing 18 tweet\n",
      "Processing 19 tweet\n",
      "Processing 20 tweet\n",
      "Processing 21 tweet\n",
      "Processing 22 tweet\n",
      "Processing 23 tweet\n",
      "Processing 24 tweet\n",
      "Processing 25 tweet\n",
      "Processing 26 tweet\n",
      "Processing 27 tweet\n",
      "Processing 28 tweet\n",
      "Processing 29 tweet\n",
      "Processing 30 tweet\n",
      "Processing 31 tweet\n",
      "Processing 32 tweet\n",
      "Processing 33 tweet\n",
      "Processing 34 tweet\n",
      "Processing 35 tweet\n",
      "Processing 36 tweet\n",
      "Processing 37 tweet\n",
      "Processing 38 tweet\n",
      "Processing 39 tweet\n",
      "Processing 40 tweet\n",
      "Processing 41 tweet\n",
      "Processing 42 tweet\n",
      "Processing 43 tweet\n",
      "Processing 44 tweet\n",
      "Processing 45 tweet\n",
      "Processing 46 tweet\n",
      "Processing 47 tweet\n",
      "Processing 48 tweet\n",
      "Processing 49 tweet\n",
      "Processing 50 tweet\n",
      "Processing 51 tweet\n",
      "Processing 52 tweet\n",
      "Processing 53 tweet\n",
      "Processing 54 tweet\n",
      "Processing 55 tweet\n",
      "Processing 56 tweet\n",
      "Processing 57 tweet\n",
      "Processing 58 tweet\n",
      "Processing 59 tweet\n",
      "Processing 60 tweet\n",
      "Processing 61 tweet\n",
      "Processing 62 tweet\n",
      "Processing 63 tweet\n",
      "Processing 64 tweet\n",
      "Processing 65 tweet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-5947c526466c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtemp_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_freqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAll Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2191\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m         \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    print(\"Processing {0} tweet\".format(i))\n",
    "    for l in X:\n",
    "        temp_dict = get_freqs(l)\n",
    "        for key in temp_dict:\n",
    "            df.at[i,key] = temp_dict[key]\n",
    "            \n",
    "print(\"\\nAll Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y, test_size = 0.35, random_state = 143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
